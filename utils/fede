import os
import uuid
import cv2

POS_PATH = os.path.join('data', 'fpositive')  #positive verification
NEG_PATH = os.path.join('data', 'negative')  #negative verification
ANC_PATH = os.path.join('data', 'fanchor')
os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))

def capture_img():
    cap = cv2.VideoCapture(0) #connection to the webcam
    while cap.isOpened(): #loop every single frame of our webcam
        ret, frame = cap.read()  #read the frame
   
        #    Cut down frame to 250x250px
        frame = frame[200:200+250,570:570+250, :]
    
        # Collect anchors 
        if cv2.waitKey(1) & 0XFF == ord('a'):
            # Create the unique file path 
            imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1())) #use uuid1 to create an unique identifier
            # Write out anchor image
            cv2.imwrite(imgname, frame)
    
        # Collect positives
        if cv2.waitKey(1) & 0XFF == ord('p'):
            # Create the unique file path 
            imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))
            # Write out positive image
            cv2.imwrite(imgname, frame)
    
        # Show image back to screen
        cv2.imshow('Image Collection', frame)
    
        # Breaking gracefully
        if cv2.waitKey(1) & 0XFF == ord('q'): #wait 1 millisecond
           break
        
    # Release the webcam
    cap.release()
    # Close the image show frame
    cv2.destroyAllWindows()
    return frame

frame = capture_img()

siamese_model = tf.keras.models.load_model('federicasiamesemodelv2.h5', 
                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})

# Make predictions with reloaded model
siamese_model.predict([test_input, test_val])

# View model summary
siamese_model.summary()

#application_data\verification_images
os.listdir(os.path.join('application_data', 'f_verification_images'))
os.path.join('application_data', 'input_image', 'input_image.jpg')

for image in os.listdir(os.path.join('application_data', 'f_verification_images')):
    validation_img = os.path.join('application_data', 'f_verification_images', image)
    print(validation_img)

def verify(model, detection_threshold, verification_threshold):
    # Build results array
    results = []
    for image in os.listdir(os.path.join('application_data', 'f_verification_images')):
        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))
        validation_img = preprocess(os.path.join('application_data', 'f_verification_images', image))
        
        # Make Predictions 
        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))
        results.append(result)

        if image==".DS_Store":

            os.remove(os. path. join('application_data', 'f_verification_images/.DS_Store'))
            print('merda removed')
    
    # Detection Threshold: Metric above which a prediciton is considered positive 
    detection = np.sum(np.array(results) > detection_threshold)
    
    # Verification Threshold: Proportion of positive predictions / total positive samples 
    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images'))) 
    print(verification)
    verified = verification > verification_threshold
    
    return results, verified

cap = cv2.VideoCapture(0)
while cap.isOpened():
    ret, frame = cap.read()
    frame = frame[200:200+250,570:570+250, :]    
    cv2.imshow('Verification', frame)
    
    # Verification trigger
    if cv2.waitKey(10) & 0xFF == ord('v'):

        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)
        # Run verification
        results, verified = verify(siamese_model, 0.7, 0.7)
        print(verified)
    
    if cv2.waitKey(10) & 0xFF == ord('q'):
        break
cap.release()
cv2.destroyAllWindows()

np.sum(np.squeeze(results) > 0.9)

#print('hello')
